{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_02_1_audio_spectrogram.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMInFyGcvQlvo69Rp7JgMQL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdIhVR8fpmzl"
      },
      "source": [
        "# \"Dynamic display of audio spectrogra of voice\"\n",
        "> \"Wanted a simple way to show the differenct frequencies we use when we talk\"\n",
        "\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: false\n",
        "- comments: true\n",
        "- categories: [audio, dsp, spectrogram, librosa]\n",
        "- image: images/spectrogram/Feb-05-2021_12-10-51_sample_audio.gif\n",
        "- hide: false\n",
        "- search_exclude: true\n",
        "- metadata_key1: metadata_value1\n",
        "- metadata_key2: metadata_value2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoM5SOK8qHmJ"
      },
      "source": [
        "#Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-h47fIwqKBI"
      },
      "source": [
        "Wanted a simple way to show that when we talk we use different frequencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9yX6sBZqXnu"
      },
      "source": [
        "#Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfA1Mfs5qZwM"
      },
      "source": [
        "\n",
        "\n",
        "*   Record sound using the computers microphone\n",
        "*   Analyze the audio with [librosa](https://librosa.org/)\n",
        "*   Display the results dynamically\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGr-9_XhrD3B"
      },
      "source": [
        "## Record sound"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJuyAdyE3FuQ"
      },
      "source": [
        "install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5IL_1U3w1mV",
        "outputId": "5307acb8-f1e4-4209-fcfc-9640dab5b497"
      },
      "source": [
        "#hide_show\n",
        "!pip install pyaudio"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached https://files.pythonhosted.org/packages/ab/42/b4f04721c5c5bfc196ce156b3c768998ef8c0ae3654ed29ea5020c749a6b/PyAudio-0.2.11.tar.gz\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.11-cp36-cp36m-linux_x86_64.whl size=51612 sha256=acf9d048ae98e47a7f527e792f054bba54872e086016a17c761493dd93f31357\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/a8/a4/292214166c2917890f85b2f72a8e5f13e1ffa527c4200dcede\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNLcxZV63JrN"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRO28MjfrJh2"
      },
      "source": [
        "#hide_show\n",
        "\n",
        "import pyaudio\n",
        "import time\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython import display"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxkvHECs3P3q"
      },
      "source": [
        "function for displaying spectrogram of audio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRV29QKqxAp2"
      },
      "source": [
        "def plot_spectrogram(wave_data, sr=44100, DIV=4, n_fft=2048, hop_length=512):\n",
        "\n",
        "    plt.clf()\n",
        "    D = np.abs(librosa.stft(wave_data, n_fft=n_fft,  hop_length=hop_length))\n",
        "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='linear')\n",
        "\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0u8P8BDy_R7"
      },
      "source": [
        "Code below works directly on a pc in a jupyter notebook,(NOT on a virtual machine. This wont work in colab)\n",
        "\n",
        "Continuously stream audio to spectrogram for analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de4BebJixDjr"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = [15, 15]\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "frames = []\n",
        "max_frames = 50\n",
        "RATE = 44100\n",
        "BUFFER_SIZE = 1024 * 2\n",
        "\n",
        "def callback(in_data, frame_count, time_info, status):\n",
        "    frames.append(np.frombuffer(in_data, dtype=np.int16))\n",
        "    if len(frames) > max_frames:\n",
        "        frames.pop(0)\n",
        "    return (in_data, pyaudio.paContinue)\n",
        "\n",
        "start_t = time.time() \n",
        "\n",
        "stream = p.open(format=pyaudio.paInt16,\n",
        "                channels=1,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=BUFFER_SIZE,\n",
        "                stream_callback=callback)\n",
        "\n",
        "stream.start_stream()\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        \n",
        "        if len(frames) >= 4:\n",
        "            \n",
        "            wave_data = np.concatenate( tuple(frames[-20:]) )\n",
        "            wave_data=wave_data/9000.\n",
        "\n",
        "            plot_spectrogram(wave_data)\n",
        "        \n",
        "        time.sleep(0.01)\n",
        "                \n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "\n",
        "print(\"stop stream\")\n",
        "stream.stop_stream()\n",
        "\n",
        "stream.close()\n",
        "p.terminate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg68GXct7Opq"
      },
      "source": [
        "# example of raw data being captured and analyzed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePom1q0-4T6q"
      },
      "source": [
        "![hello world](https://raw.githubusercontent.com/patrick-hanley/thought_experiments/master/images/spectrogram/Feb-05-2021_12-10-51_sample_audio.gif)"
      ]
    }
  ]
}